# ğŸ§  Fine-Tuning LLaMA with PEFT for Question-Answering Tasks using UnSLoTh

This project focuses on fine-tuning the :contentReference[oaicite:1]{index=1} model using :contentReference[oaicite:2]{index=2} (Parameter-Efficient Fine-Tuning) and the :contentReference[oaicite:3]{index=3} library for Question-Answering tasks.

The goal is to adapt a large language model to specific QA data and improve performance with efficient tuning techniques.

---

## ğŸ¯ What This Project Does

- Loads the LLaMA base model  
- Applies PEFT techniques for fine-tuning (e.g., LoRA, Adapters, etc.)  
- Uses UnSLoTh library for efficient training and evaluation  
- Fine-tunes the model on QA datasets  
- Evaluates the modelâ€™s performance in answering domain-specific questions  

---

## ğŸ” Key Libraries & Tools

- LLaMA (base large language model)  
- PEFT (Parameter-Efficient Fine Tuning)  
- UnSLoTh (efficient training framework)  
- Transformers / HuggingFace ecosystem  
- Google Colab environment  

---

## ğŸŒ± Learning Purpose

This project is part of my learning journey in **LLMs, fine-tuning strategies, and QA system development**.

---

## ğŸ™ Credits & Acknowledgment

I followed and learned from tutorials by Krish Naik, which guided me through fine-tuning a large model with PEFT.  
Thank you to Krish Naik for the educational content and inspiration.

YouTube Channel: https://www.youtube.com/@krishnaik06


